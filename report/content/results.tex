% (c) 2014 Michiel Appelman
\section{Results} % (fold)
\label{sec:results}

The features and limitations of the three discussed technologies in Section~\ref{sec:implementation} are given in Table~\ref{tb:reqs}. In this section we will compare the contemporary technologies with the OpenFlow implementation when implementing the \ac{dvpn} service as discribed in Section~\ref{sec:dvpns}.

\begin{table}[h]
	\centering
	\begin{tabular}{r|lll}
	 & \acs{spb} & \acs{mpls} & OpenFlow / \acs{sdn}\\
	\hline
	Tagging of VPN Traffic & \acs{pbb} & \acs{vpls} (\acs{mpls}) & \acs{pbb} / \acs{mpls}\\
	MAC Scalability & yes & yes & yes\\
	Topology Discovery & \acs{isis} & \acs{ospf} & application\\
	Path Provisioning & \acs{spt} & \acs{rsvp} / \acs{ldp} & application\\
	Traffic Engineering & limited & \acs{rsvp} & application\\
	\ac{ecmp} & limited & yes & yes, using Groups\\
	\ac{bum} limiting & dependent on \acs{hw} & dependent on \acs{hw} & yes, using Metering\\
	Exchange \acsp{cmac} & no & \ac{evpn} (draft) & application\\
	Ingress Rate Limiting & dependent on \acs{hw} & dependent on \acs{hw} & yes, using Queues or Metering\\
	Fast Failover & no & \acs{frr} & yes, using Groups\\
	\acs{oam} & 802.1ag / Y.1731 & \acs{lsp} Ping / \acs{bfd} & application\\
	\hline
	Forwarding Decision & \acs{pbb} tags & \acs{mpls} labels & flow entry \\
	\ac{bum} traffic handling & flood & flood & sent to controller\\
	\end{tabular}
	\caption{Feature requirements available in discussed technologies.}
	\label{tb:reqs}
\end{table}


\subsection{\acs{spb}} % (fold)
\label{sub:r-spb}

The \ac{spb} architecture allows for a scalable carrier network supporting thousands, even millions of \acp{dvpn} using the \ac{isid} in the \ac{pbb} frame. From our theoretical implementation in Section~\ref{ssub:spb}, it became evident that setting up a \acp{dvpn} requires little configuration. The \ac{isid} only needs to be configured on the \ac{pe} connecting the \ac{ce} port and the \ac{isis} routing protocol distributes this binding to the other corresponding \acp{pe}. Another benefit is the use of Ethernet \ac{oam} standards that are mature and extensive to allow for precise monitoring and troubleshooting.

However, the simplicity of the architecture comes at a cost. The protocols has:
\begin{itemize}
	\item limited explicit or constraints-based routing, meaning few \ac{te} features,
	\item limited \ac{ecmp} functionality due to the infancy of the standard to support it, and
	\item because, failure recovery depends on \ac{isis} reconvergence, no fast failover.
\end{itemize}

These limitations are being worked on by the community, e.g.\ IEEE 802.1Qbp which provides extensive \ac{ecmp} functions. And since the technology has only been officially standardized since March 2012, it will also need to mature before it is suitable for carrier implementations.  

Because of the shortcomings of \ac{spb} with regards to the use-case set forth in Section~\ref{sec:dvpns}, we will omit this technology in our comparison. Instead we will focus on comparing the \ac{mpls} setup from Section~\ref{ssub:mpls} with the \acs{sdn}/OpenFlow architecture as designed in Section~\ref{sub:openflow}.

% subsection r-spb (end)

\subsection{Comparison} % (fold)
\label{sub:comparison}

To get an overview of the key differences between the two architectures we will follow the structure of the \ac{dvpn} requirement list defined in Section~\ref{sec:dvpns}. 

\subsubsection{Service} % (fold)
\label{ssub:service}

From a customer point-of-view it should be of no concern how the \ac{dvpn} service is implemented in the provider network. Moreover, the \acp{pe} and the rest of provider network should be completely transparent. As such, the two technologies do not show any difference in their implementation. Both technologies are able to 
\begin{inparaenum}[\itshape 1\upshape)]
	\item provide a Layer 2 broadcast domain,
	\item connect \acp{ce} without any required \ac{vpn} configuration on them, and
	\item be completely transparent to the \acp{ce}.
\end{inparaenum}

% subsubsection service (end)

\subsubsection{Transport} % (fold)
\label{ssub:transport}

Both implementations use \ac{mpls} labels to transport frames through the network. By using labels to identify and route traffic over paths instead of a hop-by-hop based routing protocol that uses an egress \ac{pe} identifier, both technologies allow for granular \ac{te} features.   The usage of paths also means that the \acp{p} will forward the traffic without relying on or being aware of any \acp{cmac}, providing scalability. OpenFlow supports \ac{mpls} labels since version 1.1. Version 1.0 can only separate traffic using C-\ac{vlan} tags, which means that 
\begin{inparaenum}[\itshape a\upshape)]
	\item the customer \acp{mac} will need to be present in the backbone, 
	\item the customer can not use \acp{vlan} over the provider network, and
	\item forwarding will be based on the egress \ac{pe}, not the path, eliminating \ac{te}.
\end{inparaenum}
This latter limitation can of course be overcome using more specific match entries for every traffic flow that needs to be forwarded in certain way, however this would negate the benefit of using \ac{mpls} labels to minimize the amount of flows needed in the backbone. These specific flows are called `microflows' and while giving more precise control over traffic, they will fill up the flow tables of \acp{p} fairly quickly in a provider network with thousands of customers. The only way for OpenFlow to scale up to a carrier network level is by using version 1.1 or later.

Comparing \ac{mpls} to the \ac{vc}-based \ac{atm} protocol which required configuration of \acp{vc} throughout the network, we find that \ac{mpls} has the benefit of automatically distributing labels which allows for scalable and easily configurable carrier networks. The \acp{lsp} in \ac{mpls} are very comparable to the \acp{vc} of \ac{atm} \cite{mpls-tunnels}. Managing and configuring \acp{vc} was a problem in the \ac{atm} days though, mainly because of the lack of integration between the \ac{atm} switches and \ac{ip} routers. So \ac{ldp} was a huge advantage in the eyes of the carriers in the early days of \ac{mpls}. However, with the advent of explicit routes using \ac{rsvp} for \acl{te}, operators are now trying to do away with the automatic paths setup by \ac{ldp}. With these strict forwarding controls they are but a small step removed from once again manually setting up \acp{vc}. 

As mentioned before, OpenFlow will also need to provide path-based forwarding to provide scalability in the network and this has to be implemented with strict control over the labels in each \ac{pe} and \ac{p}. However, the advantage that operators have today is that the complete control plane of the network will be in the OpenFlow controller and its applications. The \ac{atm} setup required separate management for the \ac{atm} switches and the \ac{ip} routing subsystems such as the \ac{igp} and \ac{bgp} with limited integration between the two.

Discovering the network topology of a distributed network requires connectivity between the devices on Layer 2 or 3 (depending on the \ac{igp}) before any information can be exchanged. 

\acl{te} 

ECMP

FRR
\begin{itemize}
	\item Lacks standard for liveness monitoring in forwarding plane - and over complete paths.
\end{itemize}

MAC learning in control in draft E-VPN


% subsubsection transport (end)

\subsubsection{Provisioning} % (fold)
\label{ssub:provisioning}

MPLS:
\begin{itemize}
	\item initial setup complicated
	\item DVPN setup: only each PE with member port
	\item 
\end{itemize}

OF:
\begin{itemize}
	\item initial setup nonexistent, no VPNs = no flows (except LLDP/OAM)
	\item DVPN setup: every PE with member port + Ps in path
	\item 1.0 supported almost everywhere, 1.1 and 1.2 are not. 1.3 slowly coming. 
	\item TE more intricate algorithms on faster hardware (knapsack problem)
\end{itemize}

1.3 Controllers:
Ryu by NTT \cite{ryu}
NOX extensions by CPqD research center from Brasil \cite{cpqd}
M\"{u}L from kulcloud (South-Korea) is coming \cite{mul}

OpenDaylight controller still lacks 1.3 support

\HRule

The strength of these applications however, is the fact that operators can integrate their \ac{nms} and control plane even more. This allows for a more granular control over their traffic.

MPLS automation software written for DVPNs, but not due to lack of programmable consistent interface to HW, not portable to other vendor, sometimes even model!

complexity high due to intricate dependencies of different protocols

\HRule

OF applications need to solve from ground up, topology, etc... nortbound interface undefined, limited portability of apps between controllers. 


\ac{mpls} \acp{vpn} in OpenFlow: \cite{mpls-vpn-openflow}

\ac{mpls} control plane in OpenFlow: \cite{mpls-open}

Also: access layer intelligence.


% subsubsection provisioning (end)





% subsection comparison (end)





% section results (end)